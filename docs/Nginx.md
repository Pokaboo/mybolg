

## Nginx

### Nginx简介

- **Nginx:** 是一款开源的、跨平台的高性能web服务器，它有着高性能，稳定性高，配置简单，模块结构化，资源消耗低的优点。同时支持反向代理、负载均衡、缓存的功能。其采用多进程+epoll(IO多路复用)模型，也对互联网高并发连接业务有着很好的支持.
- **Nginx:** 以事件驱动的方式编写，所以有非常好的性能，同时也是一个非常高效的反向代理、负载平衡服务器。在性能上，**Nginx**占用很少的系统资源，能支持更多的并发连接，达到更高的访问效率；在功能上，**Nginx**是优秀的代理服务器和负载均衡服务器；在安装配置上，**Nginx**安装简单、配置灵活。**Nginx**支持热部署，启动速度特别快，还可以在不间断服务的情况下对软件版本或配置进行升级，即使运行数月也无需重新启动。在微服务的体系之下，**Nginx**正在被越来越多的项目采用作为网关来使用，配合**Lua**做限流、熔断等控制。

### 请求Nginx默认页面

- 浏览器输入IP（HTTP协议）——>Nginx（服务器）——>监听80端口——>找到server——>映射路由——>HTML
[![60GY0P.png](https://s3.ax1x.com/2021/03/14/60GY0P.png)](https://imgtu.com/i/60GY0P)

### Nginx进程模型

- master进程：主进程
- worker进程：工作进程
[![60JJgJ.png](https://s3.ax1x.com/2021/03/14/60JJgJ.png)](https://imgtu.com/i/60JJgJ

### Worker抢占机制
- 传统服务器事件处理
    - 同步阻塞 
    - client1——>worker1<——Master  ：80 当默认开启一个woker1进程。当处理client1阻塞时，当有新的请求进入时 client2、client3.新的的请求是不能被worker1处理。只有当client1处理完毕后才会处理其他请求。此时master会重新fork一个woker2处理client2和client3.当client阻塞时。master又会fork一个woker3去处理client3的请求。这就是传统的同步阻塞。当并发达到一定程度时。服务器会开很多进程去处理请求，对于资源开销非常大
[![60tPfS.png](https://s3.ax1x.com/2021/03/14/60tPfS.png)](https://imgtu.com/i/60tPfS)

- Nginx事件处理
    - 异步非阻塞 
    - client1——>worker1<——Master  ：80   当处理client1阻塞时。此时client2和client3发起请求时，由于Nginx异步非阻塞的，woker1会去处理client2和client3.这是由于Nginx的epoll模型
[![60tFSg.png](https://s3.ax1x.com/2021/03/14/60tFSg.png)](https://imgtu.com/i/60tFSg)

### 同步与异步，阻塞与非阻塞

- **同步阻塞：** 客户端发送请求给服务端，此时服务端处理任务时间很久，则客户端则被服务端堵塞了，所以客户端会一直等待服务端的响应，此时客户端不能做
事，服务端也不会接受其他客户端的请求。这种通信机制比较简单粗暴，但是效率不高

- **同步非阻塞：** 客户端发送请求给服务端，此时服务端处理任务时间很久，这个时候虽然客户端会一直等待响应，但是服务端可以处理其他的请求，过一会回来
的。这种方式很高效，一个服务端可以处理很多请求，不会在因为任务没有处理完而堵着，所以这是非阻塞的。

- **异步阻塞：** 客户端发送请求给服务端，此时服务端处理任务时间很久，但是客户端不会等待服务器响应，它可以做其他的任务，等服务器处理完毕后再把结果
端，客户端得到回调后再处理服务端的响应。这种方式可以避免客户端一直处于等待的状态，优化了用户体验，其实就是类似于网页里发起的ajax异步请求

- **异步非阻塞：** 客户端发送请求给服务端，此时服务端处理任务时间很久，这个时候的任务虽然处理时间会很久，但是客户端可以做其他的任务，因为他是异步
回调函数里处理响应；同时服务端是非阻塞的，所以服务端可以去处理其他的任务，如此，这个模式就显得非常的高效了

```
以上四点，除了第三点，其余的分别为BIO/NIO/AIO，面试官如果问你“请简述一下BIO/NIO/AIO之间的概念与区别” ，那么你就可以组织一下语言来回答
下生活实例来阐述也是可以的：
1. BIO： 我去上厕所，这个时候坑位都满了，我必须等待坑位释放了，我才能上吧？！此时我啥都不干，站在厕所里盯着，过了一会有人出来了，我就赶紧蹲上
2. NIO： 我去上厕所，这个时候坑位都满了，没关系，哥不急，我出去抽根烟，过会回来看看有没有空位，如果有我就蹲，如果没有我出去接着抽烟或者玩会手
3. 异步阻塞： 我去上厕所，这个时候坑位都满了，没事我等着，等有了新的空位，让他通知我就行，通知了我，我就蹲上去。
4. AIO： 我去上厕所，这个时候坑位都满了，没事，我一点也不急，我去厕所外面抽根烟再玩玩手机，等有新的坑位释放了，会有人通知我的，通知我了，我就
了。
从这个生活实例中能可以看得出来：
同步就是我需要自己每隔一段时间，以轮训的方式去看看有没有空的坑位；
异步则是有人拉完茅坑会通知你，通知你后你再回去蹲；
阻塞就是在等待的过程中，你不去做其他任何事情，干等着；
非阻塞就是你再等待的过程中可以去做其他的事，比如抽烟、喝酒、烫头、玩手机。
小结： 异步的优势显而易见，大大优化用户体验， 非阻塞使得系统资源开销远远小于阻塞模式，因为系统不需要创建新的进程(或线程)，大大地节省了系统
多出来的系统资源可以给其他的中间件去服务了。
```

### nginx.conf配置结构

- - main：全局配置
- event：配置工作模式（默认使用epoll）以及连接数
- http：http模块相关配置
   - server：虚拟主机配置，可以有多个
   - location：路由规则，表达式
   - upstream：集群，内外服务器

[![60rA6f.png](https://s3.ax1x.com/2021/03/14/60rA6f.png)](https://imgtu.com/i/60rA6f)

### nginx跨域以及防盗链配置

- 跨域：

  ```
  #允许跨域请求的域，*代表所有
  add_header 'Access-Control-Allow-Origin' *;
  #允许带上cookie请求
  add_header 'Access-Control-Allow-Credentials' 'true';
  #允许请求的方法，比如 GET/POST/PUT/DELETE
  add_header 'Access-Control-Allow-Methods' *;
  #允许请求的header
  add_header 'Access-Control-Allow-Headers' *;
  ```

  

- 防盗链配置：

  ```
  #对源站点验证
  valid_referers *.pokaboo.com;
  #非法引入会进入下方判断
  if ($invalid_referer) {
  	return 404;
  }
  ```

### Nginx集群负载均衡
- 七层、四层负载均衡

  | 层级   | 名称       | 说明                                     |
  | ------ | ---------- | ---------------------------------------- |
  | 第七层 | 应用层     | 与用户行为交互                           |
  | 第六层 | 表示层     | 定义数据格式以及数据加密                 |
  | 第五层 | 会话层     | 创建、管理以及销毁会话                   |
  | 第四层 | 传输层     | 创建、管理请求端到响应端（端到端）的连接 |
  | 第三层 | 网络层     | 请求端的IP地址                           |
  | 第二层 | 数据链路层 | 提供介质访问与链路管理                   |
  | 第一层 | 物理层     | 传输介质，物理媒介                       |

- 负载均衡-轮询
- 负载均衡-权重
- ip_hash(哈希算法)
- Keepalived 提高吞吐量:可以保证用户访问可以请求到上游服务中的固定的服务器，前提是用户ip没有发生更改

### 负载均衡原理
- hash算法：
    - 问题：
- 一致性hash算法： 一致性Hash算法是在Hash算法的基础上实现的，用于解决互联网中热点Hotspot问题，将来自网络上的流量动态的划分到不同的服务器处理。使用一致性Hash算法将流量均匀分发到不同服务器的做法是：
    - 1、求出不同服务器的哈希值，然后映射到一个范围为0 — 2^32-1的数值空间的圆环中，即将首(0)和尾(2^32-1)相接的圆环，如下图
[![6fu1a9.jpg](https://s4.ax1x.com/2021/03/19/6fu1a9.jpg)](https://imgtu.com/i/6fu1a9)
    - 2、当有一个李四的用户访问时，就会给该用户分配一个随机数，该随机数映射到圆环中的任意一个地方，按照圆环顺时针的方向查找距离最近的服务器，然后处理李四用户的请求。如果找不到服务器，则有第一台服务器来处理。
    - 注：以上是两种Hash算法的简单介绍和对比，Hash算法在信息处理、信息安全方面应用广泛，而一致性hash算法主要应用是互联网分布式场景、大数据领域等。在复杂场景下，以上一致性hash算法是有缺陷，通过以下两方面来适用复杂随机应用场景 
- 一致性Hash算法的容错性和可扩展性：现假设Node C不幸宕机，可以看到此时对象A、B、D不会受到影响，只有C对象被重定位到Node D。一般的，在一致性Hash算法中，如果一台服务器不可用，则受影响的数据仅仅是此服务器到其环空间中前一台服务器（即沿着逆时针方向行走遇到的第一台服务器）之间数据，其它不会受到影响，如下所示：
[![6fulVJ.jpg](https://s4.ax1x.com/2021/03/19/6fulVJ.jpg)](https://imgtu.com/i/6fulVJ)
- Hash环的数据倾斜问题：一致性Hash算法在服务节点太少时，容易因为节点分部不均匀而造成数据倾斜（被缓存的对象大部分集中缓存在某一台服务器上）问题，例如系统中只有两台服务器，其环分布如下：
[![6fuMb4.jpg](https://s4.ax1x.com/2021/03/19/6fuMb4.jpg)](https://imgtu.com/i/6fuMb4)
此时必然造成大量数据集中到Node A上，而只有极少量会定位到Node B上。为了解决这种数据倾斜问题，一致性Hash算法引入了虚拟节点机制，即对每一个服务节点计算多个哈希，每个计算结果位置都放置一个此服务节点，称为虚拟节点。具体做法可以在服务器IP或主机名的后面增加编号来实现。

- 负载均衡之url_hash:根据每次请求的url地址，hash后访问到固定的服务器节点。
- 负载均衡之least_conn:最少连接数
























